---
title: LangChain ğŸ¦œï¸ğŸ”— ä¸ çŸ¥è¯†åº“é—®ç­”å®è·µ
date: 2024-02-20 16:21:00 +0800

media_subpath: "/assets/img/posts/2024-02-20-langchain3"
categories: [æ·±åº¦å­¦ä¹ ]
tags: [å®éªŒ,LLM]
---

> æŸ¥çœ‹ [jupyter notebook](https://gitee.com/horizon-mind/qmmms-py-torch-practice/blob/master/%E4%BB%A3%E7%A0%81/qms_21_langchain%20%E4%B8%8E%20%E7%9F%A5%E8%AF%86%E5%BA%93%E9%97%AE%E7%AD%94%E5%AE%9E%E8%B7%B5.ipynb)
{: .prompt-info }

## å¤ä¹ ä¸å‡†å¤‡

```python
import os
from openai import OpenAI

os.environ['HTTP_PROXY'] = 'http://127.0.0.1:xxxxxx'
os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:xxxxxx'
os.environ["OPENAI_API_KEY"] = "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
```

Document loadersï¼ˆæ–‡æ¡£åŠ è½½ï¼‰æ—¨åœ¨ä»æºä¸­åŠ è½½æ•°æ®æ„å»º Documentã€‚LangChain ä¸­ Documentæ˜¯åŒ…å«æ–‡æœ¬å’Œä¸å…¶å…³è”çš„å…ƒæ•°æ®ã€‚LangChain ä¸­åŒ…å«åŠ è½½ç®€å• txt æ–‡ä»¶çš„æ–‡æ¡£åŠ è½½å™¨ï¼Œç”¨äºåŠ è½½ä»»ä½•ç½‘é¡µçš„æ–‡æœ¬å†…å®¹çš„åŠ è½½å™¨ï¼Œç”šè‡³è¿˜åŒ…å«ç”¨äºåŠ è½½ YouTube è§†é¢‘çš„è½¬å½•ç¨¿çš„åŠ è½½å™¨ã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ªæœ€ç®€å•çš„ä»æ–‡ä»¶ä¸­è¯»å–æ–‡æœ¬åŠ è½½æ•°æ®çš„ Document çš„ç¤ºä¾‹ï¼š


```python
from langchain.document_loaders import TextLoader

loader = TextLoader("./txt/dutai.txt", encoding="utf-8")
loader.load()
```


    [Document(page_content='ã€Šäººå·¥æ™ºèƒ½åŸºç¡€ã€‹æ˜¯......

Document transformersï¼ˆæ–‡æ¡£è½¬æ¢ï¼‰æ—¨åœ¨å¤„ç†æ–‡æ¡£ï¼Œä»¥å®Œæˆå„ç§è½¬æ¢ä»»åŠ¡ï¼Œå¦‚å°†æ–‡æ¡£æ ¼å¼åŒ–ä¸ºQ&A å½¢å¼ï¼Œå»é™¤æ–‡æ¡£ä¸­çš„å†—ä½™å†…å®¹ç­‰ï¼Œä»è€Œæ›´å¥½åœ°æ»¡è¶³ä¸åŒåº”ç”¨ç¨‹åºçš„éœ€æ±‚ã€‚ä¸€ä¸ªç®€å•çš„æ–‡æ¡£è½¬æ¢ç¤ºä¾‹æ˜¯å°†é•¿æ–‡æ¡£åˆ†å‰²æˆè¾ƒå°çš„éƒ¨åˆ†ï¼Œä»¥é€‚åº”ä¸åŒæ¨¡å‹çš„ä¸Šä¸‹æ–‡çª—å£å¤§å°ã€‚LangChain ä¸­æœ‰è®¸å¤šå†…ç½®çš„æ–‡æ¡£è½¬æ¢å™¨ï¼Œä½¿æ‹†åˆ†ã€åˆå¹¶ã€è¿‡æ»¤å’Œå…¶ä»–æ“ä½œæ–‡æ¡£å˜å¾—å¾ˆå®¹æ˜“ã€‚ä»¥ä¸‹æ˜¯å¯¹é•¿æ–‡æ¡£è¿›è¡Œæ‹†åˆ†çš„ä»£ç ç¤ºä¾‹ï¼š


```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

with open("./txt/dutai.txt", "r", encoding="utf-8") as f:
    state_of_the_union = f.read()
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,  # æ¯ä¸ªå—çš„é•¿åº¦æœ€å¤§ä¸º 500 ä¸ªå­—ç¬¦
    )
    texts = text_splitter.create_documents([state_of_the_union])

for text in texts:
    print(text)
```

    page_content='ã€Šäººå·¥æ™ºèƒ½åŸºç¡€ã€‹æ˜¯å¤§......


Text embedding modelsï¼ˆæ–‡æœ¬åµŒå…¥æ¨¡å‹ï¼‰æ—¨åœ¨å°†éç»“æ„åŒ–æ–‡æœ¬è½¬æ¢ä¸ºåµŒå…¥è¡¨ç¤ºã€‚åŸºäºæ–‡æœ¬çš„åµŒå…¥è¡¨ç¤ºï¼Œå¯ä»¥è¿›è¡Œè¯­ä¹‰æœç´¢ï¼ŒæŸ¥æ‰¾æœ€ç›¸ä¼¼çš„æ–‡æœ¬ç‰‡æ®µã€‚Embeddings ç±»åˆ™æ˜¯ç”¨äºä¸æ–‡æœ¬åµŒå…¥æ¨¡å‹è¿›è¡Œäº¤äº’ï¼Œå¹¶ä¸ºä¸åŒçš„åµŒå…¥æ¨¡å‹æä¾›ç»Ÿä¸€æ ‡å‡†æ¥å£ï¼ŒåŒ…æ‹¬ OpenAIã€Cohere ç­‰ã€‚LangChain ä¸­çš„ Embeddingsç±»å…¬å¼€äº†ä¸¤ä¸ªæ–¹æ³•ï¼šä¸€ä¸ªç”¨äºæ–‡æ¡£åµŒå…¥è¡¨ç¤ºï¼Œå¦ä¸€ä¸ªç”¨äºæŸ¥è¯¢åµŒå…¥è¡¨ç¤ºã€‚å‰è€…è¾“å…¥å¤šä¸ªæ–‡æœ¬ï¼Œåè€…è¾“å…¥å•ä¸ªæ–‡æœ¬ã€‚


```python
from langchain_openai import OpenAIEmbeddings

embeddings_model = OpenAIEmbeddings()
embeddings = embeddings_model.embed_documents(
    [
        "Hi there!",
        "Oh, hello!",
        "What's your name?",
        "My friends call me World",
        "Hello World!"
    ]
)
print((len(embeddings)), len(embeddings[0]))
embedded_query = embeddings_model.embed_query("What was the name mentioned in this session?")
print(embedded_query[:5])
```

    5 1536
    [0.0071710232714532396, 0.00038795966115911845, 0.02249002941018872, 0.0038081521876218607, -0.007490030552940845]


Vector Storesï¼ˆå‘é‡å­˜å‚¨ï¼‰æ˜¯å­˜å‚¨å’Œæ£€ç´¢éç»“æ„åŒ–æ•°æ®çš„ä¸»è¦æ–¹å¼ä¹‹ä¸€ã€‚å®ƒé¦–å…ˆå°†æ•°æ®è½¬åŒ–ä¸ºåµŒå…¥è¡¨ç¤ºï¼Œç„¶åå­˜å‚¨è¿™äº›ç”Ÿæˆçš„åµŒå…¥å‘é‡ã€‚åœ¨æŸ¥è¯¢é˜¶æ®µï¼Œç³»ç»Ÿä¼šåˆ©ç”¨è¿™äº›åµŒå…¥å‘é‡æ¥æ£€ç´¢ä¸æŸ¥è¯¢å†…å®¹â€œæœ€ç›¸ä¼¼â€çš„æ–‡æ¡£ã€‚å‘é‡å­˜å‚¨çš„ä¸»è¦ä»»åŠ¡æ˜¯ä¿å­˜è¿™äº›åµŒå…¥æ•°æ®å¹¶æ‰§è¡ŒåŸºäºå‘é‡çš„æœç´¢ã€‚LangChainèƒ½å¤Ÿä¸å¤šç§å‘é‡æ•°æ®åº“é›†æˆï¼Œå¦‚ Chromaã€FAISS å’Œ Lance ç­‰ã€‚ä»¥ä¸‹ç»™å‡ºäº†ä½¿ç”¨ FAISS å‘é‡æ•°æ®åº“çš„ä»£ç ç¤ºä¾‹ï¼š


```python
from langchain.document_loaders import TextLoader
from langchain_openai import OpenAIEmbeddings
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import FAISS

# Load the document, split it into chunks, embed each chunk and load it into the vector store.
raw_documents = TextLoader("./txt/dutai.txt", encoding="utf-8").load()
text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=0)
documents = text_splitter.split_documents(raw_documents)
db = FAISS.from_documents(documents, OpenAIEmbeddings())
# Do Simiarity Search
query = "å› ä¸ºè¿™é—¨è¯¾æ˜¯å»å¹´æ–°å¼€çš„ï¼Œæ‰€ä»¥å‚è€ƒä¼šå¾ˆå°‘ã€‚"
docs = db.similarity_search(query)
print(docs[0].page_content)

```

    å½“ç„¶ï¼Œè¿™é—¨è¯¾ä¹Ÿæœ‰äº®ç‚¹ã€‚æœ€åå¤ä¹ åœ¨çœ‹pptçš„æ—¶å€™ï¼Œæˆ‘å‘ç°......


Retrieversï¼ˆæ£€ç´¢å™¨ï¼‰æ˜¯ä¸€ä¸ªæ¥å£ï¼Œå…¶åŠŸèƒ½æ˜¯åŸºäºéç»“æ„åŒ–æŸ¥è¯¢è¿”å›ç›¸åº”çš„æ–‡æ¡£ã€‚æ£€ç´¢å™¨ä¸éœ€è¦å­˜å‚¨æ–‡æ¡£ï¼Œåªéœ€è¦èƒ½æ ¹æ®æŸ¥è¯¢è¿”å›ç»“æœå³å¯ã€‚å¯ä»¥é€šè¿‡get_relevant_documentsæ–¹æ³•æˆ–è€…é€šè¿‡å¼‚æ­¥è°ƒç”¨aget_relevant_documentsæ–¹æ³•è·å¾—ä¸æŸ¥è¯¢æœ€ç›¸å…³çš„æ–‡æ¡£ã€‚

åŸºäºå‘é‡å­˜å‚¨çš„æ£€ç´¢å™¨ï¼ˆVector store-backed retrieverï¼‰æ˜¯ä½¿ç”¨å‘é‡å­˜å‚¨æ£€ç´¢æ–‡æ¡£çš„æ£€ç´¢å™¨ã€‚å®ƒæ˜¯å‘é‡å­˜å‚¨ç±»çš„è½»é‡çº§åŒ…è£…å™¨ï¼Œä½¿å…¶ç¬¦åˆ Retriever æ¥å£ã€‚ä½¿ç”¨å‘é‡å­˜å‚¨å®ç°çš„æœç´¢æ–¹æ³•ï¼Œå¦‚ç›¸ä¼¼æ€§æœç´¢å’Œ MMRï¼Œæ¥æŸ¥è¯¢ä½¿ç”¨å‘é‡å­˜å‚¨çš„æ–‡æœ¬ã€‚æ¥ä¸‹æ¥æ˜¯ä¸€ä¸ªåŸºäºå‘é‡å­˜å‚¨çš„æ£€ç´¢å™¨çš„ä»£ç ç¤ºä¾‹ï¼š


```python
retriever = db.as_retriever()
docs = retriever.get_relevant_documents("å› ä¸ºè¿™é—¨è¯¾æ˜¯å»å¹´æ–°å¼€çš„ï¼Œæ‰€ä»¥å‚è€ƒä¼šå¾ˆå°‘ã€‚")
print(docs[0].page_content)
```

    å½“ç„¶ï¼Œè¿™é—¨è¯¾ä¹Ÿæœ‰äº®ç‚¹ã€‚æœ€åå¤ä¹ åœ¨çœ‹pptçš„æ—¶å€™ï¼Œæˆ‘å‘ç°....


## çŸ¥è¯†åº“é—®ç­”å®è·µ

å¤§è¯­è¨€æ¨¡å‹è™½ç„¶å¯ä»¥å¾ˆå¥½çš„å›ç­”å¾ˆå¤šé¢†åŸŸçš„
å„ç§é—®é¢˜ï¼Œä½†æ˜¯ç”±äºå…¶çŸ¥è¯†æ˜¯é€šè¿‡è¯­è¨€æ¨¡å‹è®­ç»ƒä»¥åŠæŒ‡ä»¤å¾®è°ƒç­‰æ–¹å¼æ³¨å…¥åˆ°æ¨¡å‹å‚æ•°ä¸­ï¼Œå› æ­¤é’ˆ
å¯¹æœ¬åœ°çŸ¥è¯†åº“ä¸­çš„å†…å®¹ï¼Œå¤§è¯­è¨€æ¨¡å‹å¾ˆéš¾é€šè¿‡æ­¤å‰çš„æ–¹å¼æœ‰æ•ˆçš„è¿›è¡Œå­¦ä¹ ã€‚é€šè¿‡ LangChain æ¡†æ¶ï¼Œ
å¯ä»¥æœ‰æ•ˆçš„èåˆæœ¬åœ°çŸ¥è¯†åº“å†…å®¹ä¸å¤§è¯­è¨€æ¨¡å‹çš„çŸ¥è¯†é—®ç­”èƒ½åŠ›ã€‚

![](t77.png)

åŸºäº LangChain çš„çŸ¥è¯†é—®ç­”ç³»ç»Ÿæ¡†æ¶å¦‚å›¾æ‰€ç¤ºã€‚çŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿä¸»è¦åŒ…å«ä»¥ä¸‹å‡ ä¸ªä¸»è¦æ­¥éª¤ï¼š

1. æ”¶é›†é¢†åŸŸçŸ¥è¯†æ•°æ®æ„é€ çŸ¥è¯†åº“ï¼Œè¿™äº›æ•°æ®åº”å½“èƒ½å¤Ÿå°½å¯èƒ½çš„å…¨é¢è¦†ç›–é—®ç­”éœ€æ±‚ï¼›
2. å°†çŸ¥è¯†åº“ä¸­çš„å¯¹éç»“æ„æ•°æ®è¿›è¡Œæ–‡æœ¬æå–å’Œæ–‡æœ¬æ‹†åˆ†ï¼Œå¾—åˆ°æ–‡æœ¬å—ï¼›
3. åˆ©ç”¨åµŒå…¥å‘é‡è¡¨ç¤ºæ¨¡å‹ç»™å‡ºæ–‡æœ¬å—åµŒå…¥è¡¨ç¤ºï¼Œå¹¶åˆ©ç”¨å‘é‡æ•°æ®åº“è¿›è¡Œä¿å­˜
4. æ ¹æ®ç”¨æˆ·è¾“å…¥ä¿¡æ¯çš„åµŒå…¥è¡¨ç¤ºï¼Œé€šè¿‡å‘é‡æ•°æ®åº“æ£€ç´¢å¾—åˆ°æœ€ç›¸å…³æ–‡æœ¬ç‰‡æ®µï¼Œåˆ©ç”¨æç¤ºè¯æ¨¡æ¿ä¸ç”¨æˆ·è¾“å…¥ä»¥åŠå†å²æ¶ˆæ¯åˆå¹¶è¾“å…¥å¤§è¯­è¨€æ¨¡å‹ï¼›
5. å°†å¤§è¯­è¨€æ¨¡å‹ç»“æœè¿”å›ç”¨æˆ·ã€‚


```python
from langchain.document_loaders import DirectoryLoader
from langchain_openai import OpenAIEmbeddings
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import Chroma
from langchain.chains import ChatVectorDBChain, ConversationalRetrievalChain
from langchain_openai import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.prompts.chat import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    AIMessagePromptTemplate,
    HumanMessagePromptTemplate,
)

# ä»æœ¬åœ°è¯»å–ç›¸å…³æ•°æ®
loader = DirectoryLoader(
    './txt/', glob='*.txt', show_progress=True
)
docs = loader.load()

# å°†æ–‡ä»¶è¿›è¡Œåˆ‡åˆ†
text_splitter = CharacterTextSplitter(
    chunk_size=300,  # æˆ–è€… 1000
    chunk_overlap=0
)
docs_split = text_splitter.split_documents(docs)
print("len of docs_split:", len(docs_split))

# åˆå§‹åŒ– OpenAI Embeddings
embeddings = OpenAIEmbeddings()

# å°†æ•°æ®å­˜å…¥ Chroma å‘é‡å­˜å‚¨
vector_store = Chroma.from_documents(docs, embeddings)
# åˆå§‹åŒ–æ£€ç´¢å™¨ï¼Œä½¿ç”¨å‘é‡å­˜å‚¨
retriever = vector_store.as_retriever()


system_template = """
Use the following pieces of context to answer the users question.
If you don't know the answer, just say that you don't know, don't try to make up an answer.
Answering these questions in Chinese.
-----------
{question}
-----------
{chat_history}
"""

# æ„å»ºåˆå§‹ Messages åˆ—è¡¨
messages = [
    SystemMessagePromptTemplate.from_template(system_template),
    HumanMessagePromptTemplate.from_template('{question}')
]

# åˆå§‹åŒ– Prompt å¯¹è±¡
prompt = ChatPromptTemplate.from_messages(messages)

# åˆå§‹åŒ–å¤§è¯­è¨€æ¨¡å‹ï¼Œä½¿ç”¨ OpenAI API
llm=ChatOpenAI(temperature=0.1, max_tokens=2048)

# åˆå§‹åŒ–é—®ç­”é“¾
qa = ConversationalRetrievalChain.from_llm(llm,retriever,condense_question_prompt=prompt)

chat_history = []
question = "ä»Šå¹´è€ƒäº†ä»€ä¹ˆé¢˜ç›®ï¼Ÿ"
result = qa.invoke({'question': question, 'chat_history': chat_history})
chat_history.append((question, result['answer']))
print(result['answer'])
```

    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 125.42it/s]


    len of docs_split: 6
    ä»Šå¹´è€ƒè¯•çš„å¤§é¢˜åŒ…æ‹¬ä»¥ä¸‹å†…å®¹ï¼š
    
    1. èŠèŠä¸ºä»€ä¹ˆç”¨å·ç§¯ï¼Ÿå¥½å¤„ï¼Ÿ
    2. åˆ—ä¸¾ä¸€äº›äººå·¥æ™ºèƒ½ç ”ç©¶æ–¹å‘ã€çƒ­ç‚¹ã€‚
    3. Î±Î²è¿‡ç¨‹å’Œå‰ªæã€‚
    4. å·ç§¯è®¡ç®—ã€‚
    5. A*ç®—æ³•æ±‚è·¯å¾„ã€‚
    6. å½’çº¦æ³•è¯æ˜ç»“è®ºã€‚
    
    è¿™äº›æ˜¯ä»Šå¹´è€ƒè¯•çš„å¤§é¢˜å†…å®¹ã€‚


å¦‚æœè¦è¿ç»­æé—®ï¼Œä½¿ç”¨ä»¥ä¸‹ä»£ç ï¼š


```python
while True:
    question = input('é—®é¢˜ï¼š')
    # å¼€å§‹å‘é€é—®é¢˜ chat_history ä¸ºå¿…é¡»å‚æ•°, ç”¨äºå­˜å‚¨å¯¹è¯å†å²
    result = qa({'question': question, 'chat_history': chat_history})
    chat_history.append((question, result['answer']))
    print(result['answer'])
```
