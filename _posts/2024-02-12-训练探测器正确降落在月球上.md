---
title: è®­ç»ƒæ¢æµ‹å™¨æ­£ç¡®é™è½åœ¨æœˆçƒğŸŒ•ä¸Š
date: 2024-02-12 20:21:00 +0800

img_path: "/assets/img/posts/2024-02-12-è®­ç»ƒæ¢æµ‹å™¨æ­£ç¡®é™è½åœ¨æœˆçƒä¸Š"
categories: [æ·±åº¦å­¦ä¹ ]
tags: [å®éªŒ]
---

> è·‘æ¨¡å‹æ—¶é—´ï¼
>
> æ¥è‡ªHuggingFace ğŸ¤— å¼ºåŒ–å­¦ä¹ è¯¾ç¨‹
{: .prompt-info }

æˆ‘ä»¬å°†è®­ç»ƒæˆ‘ä»¬æ™ºèƒ½ä½“ï¼ˆ[æœˆçƒç€é™†å™¨](https://gymnasium.farama.org/environments/box2d/lunar_lander/)ï¼‰**æ­£ç¡®ç™»é™†æœˆçƒ**ã€‚ä¸ºæ­¤ï¼Œæ™ºèƒ½ä½“éœ€è¦å­¦ä¹ **è°ƒæ•´å…¶é€Ÿåº¦å’Œä½ç½®ï¼ˆæ°´å¹³ã€å‚ç›´å’Œè§’åº¦ï¼‰ä»¥æ­£ç¡®ç€é™†ã€‚**

![](lunarLander.gif)

æ¯ä¸€æ­¥ï¼š

- æˆ‘ä»¬çš„ä»£ç†ä» **ç¯å¢ƒä¸­**æ¥æ”¶**çŠ¶æ€ï¼ˆS0ï¼‰** â€”â€” æˆ‘ä»¬æ¥æ”¶æ¸¸æˆçš„ç¬¬ä¸€å¸§ï¼ˆç¯å¢ƒï¼‰ã€‚
- æ ¹æ®è¯¥ **çŠ¶æ€ (S0)ï¼Œ** ä»£ç†é‡‡å– **è¡ŒåŠ¨ (A0)** â€”â€” æˆ‘ä»¬çš„ä»£ç†å°†å‘å³ç§»åŠ¨ã€‚
- ç¯å¢ƒè½¬æ¢åˆ° **æ–°çŠ¶æ€ (S1)** â€”â€” æ–°æ¡†æ¶ã€‚
- ç¯å¢ƒç»™æ™ºèƒ½ä½“ä¸€äº› **å¥–åŠ±ï¼ˆR1ï¼‰** â€”â€” æˆ‘ä»¬æ²¡æœ‰æ­» *ï¼ˆæ­£å¥–åŠ±+1ï¼‰*ã€‚

## ä»»åŠ¡

**è§‚æµ‹**ç»“æœæ˜¯ä¸€ä¸ªå¤§å°ä¸º 8 çš„å‘é‡ï¼Œå…¶ä¸­æ¯ä¸ªå€¼éƒ½åŒ…å«æœ‰å…³ç€é™†å™¨çš„ä¸åŒä¿¡æ¯ï¼š

- æ°´å¹³åæ ‡ (x)
- å‚ç›´åæ ‡ (y)
- æ°´å¹³é€Ÿåº¦ï¼ˆxï¼‰
- å‚ç›´é€Ÿåº¦ï¼ˆyï¼‰
- è§’åº¦
- è§’é€Ÿåº¦
- å·¦è…¿æ¥è§¦ç‚¹æ˜¯å¦è§¦åœ°ï¼ˆå¸ƒå°”å€¼ï¼‰
- å³è…¿æ¥è§¦ç‚¹æ˜¯å¦è§¦åœ°ï¼ˆå¸ƒå°”å€¼ï¼‰

**åŠ¨ä½œç©ºé—´**ï¼ˆæ™ºèƒ½ä½“å¯ä»¥é‡‡å–çš„ä¸€ç»„å¯èƒ½åŠ¨ä½œï¼‰æ˜¯ç¦»æ•£çš„ï¼Œæœ‰ 4 ä¸ªå¯ç”¨åŠ¨ä½œğŸ®ï¼š

- è¡ŒåŠ¨ 0ï¼šä»€ä¹ˆä¹Ÿä¸åšï¼Œ
- åŠ¨ä½œ1ï¼šå¯åŠ¨å·¦æ–¹å‘å¼•æ“ï¼Œ
- åŠ¨ä½œ2ï¼šå¯åŠ¨ä¸»å¼•æ“ï¼Œ
- åŠ¨ä½œ3ï¼šå‘å³å‘å°„å®šå‘å¼•æ“ã€‚

**å¥–åŠ±å‡½æ•°**ï¼ˆåœ¨æ¯ä¸ªæ—¶é—´æ­¥ç»™å‡ºå¥–åŠ±çš„å‡½æ•°ï¼‰ğŸ’°ï¼šæ¯èµ°ä¸€æ­¥åéƒ½ä¼šç»™äºˆå¥–åŠ±ã€‚ä¸€ä¸ªepisodeçš„æ€»å¥–åŠ±æ˜¯**è¯¥episodeä¸­æ‰€æœ‰æ­¥éª¤çš„å¥–åŠ±ä¹‹å’Œ**ã€‚å¯¹äºæ¯ä¸€æ­¥ï¼Œå¥–åŠ±ï¼š

- ç€é™†å™¨ç¦»ç€é™†åœºè¶Šè¿‘/è¶Šè¿œï¼Œåˆ™å¢åŠ /å‡å°‘ã€‚
- ç€é™†å™¨ç§»åŠ¨å¾—è¶Šæ…¢/è¶Šå¿«ï¼Œåˆ™å¢åŠ /å‡å°‘ã€‚
- ç€é™†å™¨å€¾æ–œå¾—è¶Šå¤šï¼ˆè§’åº¦ä¸æ˜¯æ°´å¹³çš„ï¼‰ï¼Œè¯¥å€¼å°±è¶Šå°ã€‚
- æ¯ä¸€æ¡ä¸åœ°é¢æ¥è§¦çš„è…¿å¢åŠ  10 åˆ†ã€‚
- ä¾§å¼•æ“ç‚¹ç«æ¯å¸§å‡å°‘ 0.03 ç‚¹ã€‚
- ä¸»æœºæ¯ç‚¹ç«ä¸€å¸§å°±å‡å°‘ 0.3 ç‚¹ã€‚
- **è¯¥å‰§é›†å› å æ¯æˆ–å®‰å…¨ç€é™†è€Œåˆ†åˆ«**è·å¾—-100 æˆ– +100 åˆ†çš„é¢å¤–å¥–åŠ±ã€‚

å¦‚æœä¸€ä¸ªæƒ…èŠ‚çš„**å¾—åˆ†è‡³å°‘ä¸º 200 åˆ†ï¼Œåˆ™è¯¥æƒ…èŠ‚è¢«è§†ä¸ºä¸€ä¸ªè§£å†³æ–¹æ¡ˆã€‚**

åˆ›å»ºç¯å¢ƒä»£ç ï¼ŒåŸºäº**ç¯å¢ƒåº“** Gymnasiumï¼š

```python
# Create the environment
env = make_vec_env('LunarLander-v2', n_envs=16)
```

## æ¨¡å‹

ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ Stable-Baselines3 çš„ **Proximal Policy Optimization**ã€‚[PPO](https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html#example) æ˜¯æœ¬è¯¾ç¨‹ä¸­å­¦ä¹ çš„ SOTAï¼ˆæœ€å…ˆè¿›çš„ï¼‰æ·±åº¦å¼ºåŒ–å­¦ä¹ ç®—æ³•ä¹‹ä¸€ã€‚

PPO æ˜¯ä»¥ä¸‹å„é¡¹çš„ç»„åˆï¼š

- åŸºäºä»·å€¼çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼šå­¦ä¹ è¡ŒåŠ¨ä»·å€¼å‡½æ•°ï¼Œè¯¥å‡½æ•°å°†å‘Šè¯‰æˆ‘ä»¬åœ¨**ç»™å®šçŠ¶æ€å’Œè¡ŒåŠ¨çš„æƒ…å†µä¸‹è¦é‡‡å–çš„æœ€æœ‰ä»·å€¼çš„è¡ŒåŠ¨**ã€‚
- åŸºäºç­–ç•¥çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼šå­¦ä¹ ä¸€ä¸ªç­–ç•¥ï¼Œè¯¥ç­–ç•¥å°†ä¸º**æˆ‘ä»¬æä¾›åŠ¨ä½œçš„æ¦‚ç‡åˆ†å¸ƒ**ã€‚

åˆ›å»ºæ¨¡å‹

```python
model = PPO( 
    policy= "MlpPolicy" , 
    env=env, 
    n_steps= 1024 , 
    batch_size= 64 , 
    n_epochs= 4 , 
    gamma= 0.999 , 
    gae_lambda= 0.98 , 
    ent_coef= 0.01 , 
    verbose = 1  
)
```

è®­ç»ƒæˆ‘ä»¬çš„ä»£ç† 1,000,000 ä¸ªæ—¶é—´æ­¥ï¼Œä¸è¦å¿˜è®°åœ¨ Colab ä¸Šä½¿ç”¨ GPUã€‚å¤§çº¦éœ€è¦ 20 åˆ†é’Ÿ

```python
# Train it for 1,000,000 timesteps
model.learn(total_timesteps=1000000)
# Save the model
model_name = "ppo-LunarLander-v2"
model.save(model_name)
```

ä¸€æ¬¡å…¸å‹çš„è¿­ä»£è¿‡ç¨‹è¾“å‡ºï¼š

```
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 524         |
|    ep_rew_mean          | 19          |
| time/                   |             |
|    fps                  | 1297        |
|    iterations           | 16          |
|    time_elapsed         | 202         |
|    total_timesteps      | 262144      |
| train/                  |             |
|    approx_kl            | 0.005388215 |
|    clip_fraction        | 0.0445      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.25       |
|    explained_variance   | 0.876       |
|    learning_rate        | 0.0003      |
|    loss                 | 56.7        |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.0021     |
|    value_loss           | 111         |
-----------------------------------------
```

## è¯„ä¼°

```python
# Create a new environment for evaluation
eval_env = Monitor(gym.make("LunarLander-v2"))

# Evaluate the model with 10 evaluation episodes and deterministic=True
mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)

# Print the results
print(f"mean_reward={mean_reward:.2f} +/- {std_reward}")
```

è¾“å‡ºï¼š

```
mean_reward=262.39 +/- 20.647280625927973
```

## ä¸Šä¼ æ¨¡å‹åˆ° Hub

å‡†å¤‡ä¸€ä¸ª**å…·æœ‰ write è§’è‰²çš„**[ä»¤ç‰Œ](https://huggingface.co/settings/tokens)ã€‚åœ¨ notebook ä¸­ä½¿ç”¨ä»¤ç‰Œç™»å½•å¯ä»¥è¿è¡Œä»£ç ï¼š

```python
notebook_login()
!git config --global credential.helper store
```

å¦‚æœä¸æƒ³ä½¿ç”¨ Google Colab æˆ– Jupyter Notebookï¼Œåˆ™éœ€è¦ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼š`huggingface-cli login`

ä½¿ç”¨`package_to_hub()`å‡½æ•°å°†ç»è¿‡è®­ç»ƒçš„ä»£ç†æ¨é€åˆ° Hubï¼š

- `model`ï¼šæˆ‘ä»¬è®­ç»ƒå¥½çš„æ¨¡å‹ã€‚
- `model_name`ï¼šæˆ‘ä»¬å®šä¹‰çš„è®­ç»ƒæ¨¡å‹çš„åç§°`model_save`
- `model_architecture`ï¼šæˆ‘ä»¬ä½¿ç”¨çš„æ¨¡å‹æ¶æ„ï¼Œåœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­æ˜¯ PPO
- `env_id`ï¼šåœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­æ˜¯ç¯å¢ƒçš„åç§°`LunarLander-v2`
- `eval_env`ï¼ševal_envä¸­å®šä¹‰çš„è¯„ä¼°ç¯å¢ƒ
- `repo_id`ï¼šå°†åˆ›å»º/æ›´æ–°çš„ Hugging Face Hub å­˜å‚¨åº“çš„åç§°`repo_id = {username}/{repo_name}`

ğŸ’¡**ä¸€ä¸ªå¥½åå­—æ˜¯`{username}/{model_architecture}-{env_id}`**

```python
import gymnasium as gym
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3.common.env_util import make_vec_env

from huggingface_sb3 import package_to_hub

# repo_id is the id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name} for instance ThomasSimonini/ppo-LunarLander-v2
repo_id = "QMMMS/ppo-LunarLander-v2"

# Define the name of the environment
env_id = "LunarLander-v2"

# Create the evaluation env and set the render_mode="rgb_array"
eval_env = DummyVecEnv([lambda: Monitor(gym.make(env_id, render_mode="rgb_array"))])

#  Define the model architecture we used
model_architecture = "PPO"

# Define the commit message
commit_message = "Upload PPO LunarLander-v2 trained agent"

# method save, evaluate, generate a model card and record a replay video of your agent before pushing the repo to the hub
package_to_hub(model=model, 
               model_name=model_name,
               model_architecture=model_architecture,
               env_id=env_id, 
               eval_env=eval_env,
               repo_id=repo_id, 
               commit_message=commit_message)
```

éšåå°±èƒ½çœ‹åˆ°ä¸€ä¸ª[ä»“åº“](https://huggingface.co/QMMMS/ppo-LunarLander-v2)ä¼šè¢«è‡ªåŠ¨åˆ›å»ºï¼Œè®­ç»ƒå¥½çš„æ¨¡å‹è¢«ä¸Šä¼ ã€‚

## ä» Hub åŠ è½½æ¨¡å‹

1. å¤åˆ¶å…¶ repo_idï¼Œä¾‹å¦‚`QMMMS/ppo-LunarLander-v2`
2. ä½¿ç”¨ load_from_hub ï¼Œéœ€è¦å­˜å‚¨åº“ä¸­ä¿å­˜çš„æ¨¡å‹åŠå…¶æ‰©å±•åï¼ˆ*.zipï¼‰ï¼Œä¾‹å¦‚`ppo-LunarLander-v2.zip`

å› ä¸ºæˆ‘ä» Hub ä¸‹è½½çš„æ¨¡å‹æ˜¯ç”¨ Gymï¼ˆGymnasium çš„å‰ç‰ˆæœ¬ï¼‰è®­ç»ƒçš„ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦å®‰è£… shimmy ä¸€ä¸ª API è½¬æ¢å·¥å…·ï¼Œå®ƒå°†å¸®åŠ©æˆ‘ä»¬æ­£ç¡®è¿è¡Œç¯å¢ƒã€‚

```python
!pip install shimmy
```

```python
from huggingface_sb3 import load_from_hub
repo_id = "QMMMS/ppo-LunarLander-v2" # The repo_id
filename = "ppo-LunarLander-v2.zip" # The model filename.zip

# When the model was trained on Python 3.8 the pickle protocol is 5
# But Python 3.6, 3.7 use protocol 4
# In order to get compatibility we need to:
# 1. Install pickle5 (we done it at the beginning of the colab)
# 2. Create a custom empty object we pass as parameter to PPO.load()
custom_objects = {
            "learning_rate": 0.0,
            "lr_schedule": lambda _: 0.0,
            "clip_range": lambda _: 0.0,
}

checkpoint = load_from_hub(repo_id, filename)
model = PPO.load(checkpoint, custom_objects=custom_objects, print_system_info=True)
```

è¯„ä¼°æ¨¡å‹

```python
eval_env = Monitor(gym.make("LunarLander-v2"))
mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)
print(f"mean_reward={mean_reward:.2f} +/- {std_reward}")
```
